{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Pretrained VGG16 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Flatten, Dense\n",
    "from keras.applications.vgg16 import VGG16\n",
    "\n",
    "# Define image size\n",
    "IMAGE_SHAPE = [224, 224, 3]\n",
    "\n",
    "# Load VGG16 model (without the top layer)\n",
    "vgg_model = VGG16(input_shape=IMAGE_SHAPE, weights='imagenet', include_top=False)\n",
    "\n",
    "# Freeze all layers\n",
    "for layer in vgg_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modify the Model for Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the VGG16 output\n",
    "flatten_layer = Flatten()(vgg_model.output)\n",
    "\n",
    "# Add a Dense (Fully Connected) Layer\n",
    "fc_layer = Dense(128, activation='relu')(flatten_layer)\n",
    "\n",
    "# Output layer (Binary Classification: Normal/Pneumonia)\n",
    "output_layer = Dense(1, activation='sigmoid')(fc_layer)\n",
    "\n",
    "# Create the final model\n",
    "model = Model(inputs=vgg_model.input, outputs=output_layer)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4401 images belonging to 2 classes.\n",
      "Found 624 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Define paths\n",
    "TRAIN_DIR = \"Pneumonia Detection Dataset/chest_xray/train\"\n",
    "TEST_DIR = \"Pneumonia Detection Dataset/chest_xray/test\"\n",
    "\n",
    "# Image Augmentation for training data\n",
    "train_datagen = ImageDataGenerator(rescale=1./255, shear_range=0.2, zoom_range=0.2, horizontal_flip=True)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Load images from directories\n",
    "train_set = train_datagen.flow_from_directory(TRAIN_DIR, target_size=(224, 224), batch_size=32, class_mode='binary')\n",
    "test_set = test_datagen.flow_from_directory(TEST_DIR, target_size=(224, 224), batch_size=32, class_mode='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m583s\u001b[0m 4s/step - accuracy: 0.8167 - loss: 0.5803 - val_accuracy: 0.8830 - val_loss: 0.3338\n",
      "Epoch 2/5\n",
      "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m576s\u001b[0m 4s/step - accuracy: 0.9499 - loss: 0.1340 - val_accuracy: 0.9119 - val_loss: 0.2572\n",
      "Epoch 3/5\n",
      "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m577s\u001b[0m 4s/step - accuracy: 0.9603 - loss: 0.1062 - val_accuracy: 0.8734 - val_loss: 0.4961\n",
      "Epoch 4/5\n",
      "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m581s\u001b[0m 4s/step - accuracy: 0.9596 - loss: 0.1153 - val_accuracy: 0.9135 - val_loss: 0.2415\n",
      "Epoch 5/5\n",
      "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m599s\u001b[0m 4s/step - accuracy: 0.9665 - loss: 0.0892 - val_accuracy: 0.9151 - val_loss: 0.3104\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(train_set, validation_data=test_set, epochs=5, steps_per_epoch=len(train_set), validation_steps=len(test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.save(\"pneumonia_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xray_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
